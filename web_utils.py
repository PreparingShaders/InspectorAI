import html
import asyncio
from ddgs import DDGS

TRUSTED_SITES = [
    "reuters.com", "apnews.com", "interfax.ru", "rbc.ru",
    "kommersant.ru", "tass.ru", "ria.ru", "provereno.media",
    "bbc.com/russian", "meduza.io", "vedomosti.ru", "ru.wikipedia.org"
]

async def get_web_context(query: str, period='w'):
    try:
        with DDGS() as ddgs:
            clean_query = query.replace('"', '').strip()

            # –î–µ–ª–∞–µ–º –æ–¥–∏–Ω —à–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º —Å—Ä–∞–∑—É (—Å—Ä–µ–∑ –¥–æ 12)
            sites_filter = " OR ".join([f"site:{s}" for s in TRUSTED_SITES[:12]])
            full_query = f"{clean_query[:80]} ({sites_filter})"

            results = ddgs.text(full_query, region='ru-ru', timelimit=period, max_results=10)

            if not results:
                # –ï—Å–ª–∏ –≤ –±–µ–ª–æ–º —Å–ø–∏—Å–∫–µ –ø—É—Å—Ç–æ, –∏—â–µ–º –≤–µ–∑–¥–µ
                results = ddgs.text(clean_query[:150], region='ru-ru', max_results=5)

            if not results: return None

            # --- –õ–û–ì–ò–ö–ê –†–ï–ô–¢–ò–ù–ì–ê ---
            found_on_sites = set()
            context_parts = []

            for r in results:
                href = r.get('href', '').lower()
                for site in TRUSTED_SITES[:12]:
                    if site in href:
                        found_on_sites.add(site)

                context_parts.append(f"–ò–°–¢–û–ß–ù–ò–ö: {r.get('title')}\nURL: {href}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –¥–ª—è –Ω–µ–π—Ä–æ–Ω–∫–∏
            report = "–û–¢–ß–ï–¢ –ü–û –ú–û–ù–ò–¢–û–†–ò–ù–ì–£ –°–ú–ò:\n"
            for site in TRUSTED_SITES[:12]:
                status = "‚úÖ –ï–°–¢–¨ –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø" if site in found_on_sites else "‚ùå –ù–ï–¢ –î–ê–ù–ù–´–•"
                report += f"- {site}: {status}\n"

            report += "\n–î–ï–¢–ê–õ–ò:\n" + "\n".join(context_parts[:5])
            return report

    except Exception as e:
        print(f"üåê –û—à–∏–±–∫–∞: {e}")
        return None
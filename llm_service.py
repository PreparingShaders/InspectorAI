#llm_service
import re
import requests, telegram
from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content
from collections import defaultdict
from telegram.helpers import escape_markdown

from config import (
    GEMINI_API_KEY, OPEN_ROUTER_API_KEY, WORKER_URL,
    SYSTEM_PROMPT_INSPECTOR, SYSTEM_PROMPT_CHAT, DEFAULT_OPENROUTER_MODELS, GEMINI_MODELS, API_TIMEOUT
)
from web_utils import get_web_context
from utils import safe_format_to_html, get_model_short_name

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
or_client = OpenAI(
    api_key=OPEN_ROUTER_API_KEY,
    base_url=f"{WORKER_URL}/v1",
    timeout=API_TIMEOUT
)

gemini_client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(base_url=WORKER_URL, timeout=int(API_TIMEOUT * 1000)),
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π ---
current_free_or_models = [DEFAULT_OPENROUTER_MODELS]
GEMINI_MODEL_BY_ID = {str(i): m for i, m in enumerate(GEMINI_MODELS)}
OPENROUTER_MODEL_BY_ID = {}
chat_histories = defaultdict(list)
BLACKLISTED_MODELS = set()


def fetch_dynamic_models():
    url = "https://openrouter.ai/api/v1/models"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            all_models = response.json().get('data', [])

            # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ä—É—á–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
            result = [m for m in DEFAULT_OPENROUTER_MODELS]

            for m in all_models:
                m_id = m.get('id', '')
                pricing = m.get('pricing', {})
                is_free = pricing.get('prompt') == "0" and pricing.get('completion') == "0"

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ä—É—á–Ω–æ–º —Å–ø–∏—Å–∫–µ
                if is_free and m_id not in result and m_id != "openrouter/free":
                    if m_id not in BLACKLISTED_MODELS:
                        result.append(m_id)

            return result[:15]
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
    return DEFAULT_OPENROUTER_MODELS

# llm_service.py

current_free_or_models = []  # –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏

def update_model_mappings():
    global current_free_or_models, OPENROUTER_MODEL_BY_ID

    new_models = fetch_dynamic_models()  # –¢–≤–æ—è –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞

    if new_models:
        current_free_or_models.clear()  # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π —Å–ø–∏—Å–æ–∫
        current_free_or_models.extend(new_models)  # –ù–∞–ø–æ–ª–Ω—è–µ–º —Ç–æ—Ç –∂–µ —Å–∞–º—ã–π –æ–±—ä–µ–∫—Ç

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–ø–ø–∏–Ω–≥ ID
        OPENROUTER_MODEL_BY_ID.clear()
        for i, m in enumerate(current_free_or_models):
            OPENROUTER_MODEL_BY_ID[str(i + 100)] = m


async def process_llm(update, context, query, selected_model=None, selected_provider=None, thread_id=None, mode="chat"):
    chat_id = update.effective_chat.id
    system_instruction = SYSTEM_PROMPT_INSPECTOR if mode == "inspector" else SYSTEM_PROMPT_CHAT

    # –û–¢–ü–†–ê–í–õ–Ø–ï–ú –°–¢–ê–¢–£–° –ë–ï–ó parse_mode
    status_text = "‚ö° –†–∞–±–æ—Ç–∞—é..." if mode != "inspector" else "üîç –í—Ö–æ–∂—É –≤ —Ä–µ–∂–∏–º –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é..."
    status_msg = await context.bot.send_message(
        chat_id=chat_id,
        text=status_text,
        message_thread_id=thread_id
        # parse_mode –£–ë–†–ê–ù
    )

    final_query = query
    if mode == "inspector":
        # –†–ï–î–ê–ö–¢–ò–†–£–ï–ú –°–¢–ê–¢–£–° –ë–ï–ó parse_mode
        await context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=status_msg.message_id,
            text="üåê –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ..."
        )

        search_term = query.replace("–û–ë–™–ï–ö–¢ –ü–†–û–í–ï–†–ö–ò:", "").split("\n\n–í–û–ü–†–û–°:")[0].strip()
        web_data = await get_web_context(search_term)

        if web_data:
            # –°–ù–û–í–ê –ë–ï–ó parse_mode
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_msg.message_id,
                text="üß† –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã. –§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."
            )
            final_query = f"–î–ê–ù–ù–´–ï –ò–ó –°–ï–¢–ò:\n{web_data}\n\n–ó–ê–ü–†–û–°:\n{query}"

    # –ò—Å—Ç–æ—Ä–∏—è
    history = chat_histories[chat_id]
    history.append(Content(role="user", parts=[types.Part(text=final_query)]))
    chat_histories[chat_id] = history[-6:]

    # –û–ß–ï–†–ï–î–¨ –ú–û–î–ï–õ–ï–ô: –°–Ω–∞—á–∞–ª–∞ Trinity (–∏–ª–∏ —Ç–æ —á—Ç–æ –≤—ã–±—Ä–∞–ª —é–∑–µ—Ä), –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
    models_to_try = []
    if selected_model and selected_provider:
        models_to_try.append((selected_provider, selected_model))

    # –î–æ–±–∞–≤–ª—è–µ–º Gemini –≤ –∫–æ–Ω–µ—Ü –∫–∞–∫ –Ω–∞–¥–µ–∂–Ω—ã–π –±—ç–∫–∞–ø
    for m in GEMINI_MODELS:
        if ("gemini", m) not in models_to_try:
            models_to_try.append(("gemini", m))

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ OpenRouter
    for m in current_free_or_models:
        if ("openrouter", m) not in models_to_try:
            models_to_try.append(("openrouter", m))



    reply_text, used_model, used_prov = None, None, None

    for prov, m_path in models_to_try:
        if m_path in BLACKLISTED_MODELS:
            continue

        try:
            name_short = get_model_short_name(m_path, prov)
            await context.bot.edit_message_text(f"üîÑ –ü—Ä–æ–±—É—é {prov}: {name_short}...", chat_id, status_msg.message_id)

            if prov == "gemini":
                # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ config.py GEMINI_MODELS –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ "models/"
                resp = gemini_client.models.generate_content(
                    model=m_path,
                    contents=[Content(role="model", parts=[types.Part(text=system_instruction)])] + history
                )
                reply_text = resp.text
            else:
                messages = [{"role": "system", "content": system_instruction}]
                for h in history:
                    messages.append({"role": "user" if h.role == "user" else "assistant", "content": h.parts[0].text})

                resp = or_client.chat.completions.create(
                    model=m_path,
                    messages=messages,
                    temperature=0.7,  # –£–º–µ–Ω—å—à–∞–µ–º "—Ñ–∞–Ω—Ç–∞–∑–∏–∏", –¥–µ–ª–∞–µ–º –æ—Ç–≤–µ—Ç—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ
                    top_p=0.9,  # –û—Ç—Å–µ–∫–∞–µ–º —Å–æ–≤—Å–µ–º –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Å–ª–æ–≤–∞
                    extra_body={
                        "repetition_penalty": 1.1  # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Ñ—Ä–∞–∑—ã
                    }
                )
                reply_text = resp.choices[0].message.content

            if reply_text:
                used_model, used_prov = name_short, prov.capitalize()
                break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ {m_path}: {e}")
            # –í—Ä–µ–º–µ–Ω–Ω–æ –±–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ 401/403/404 (–º–æ–¥–µ–ª–∏ –Ω–µ—Ç –∏–ª–∏ –ª–∏–º–∏—Ç)
            if "404" in str(e) or "401" in str(e):
                BLACKLISTED_MODELS.add(m_path)

    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    # ... (–ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è reply_text –æ—Ç –º–æ–¥–µ–ª–∏)
    if reply_text:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        clean_header = escape_markdown(f"{used_prov}: {used_model}", version=2)
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–ª–æ
        formatted_body = safe_format_to_html(reply_text)

        final_text = f"*{clean_header}*\n\n{formatted_body}"

        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∞—Å–∏–≤–æ
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_msg.message_id,
                text=final_text,
                parse_mode="MarkdownV2"
            )
        except Exception as e:
            # –ü–õ–ê–ù –ë: –ï—Å–ª–∏ MarkdownV2 ¬´–≤–∑—Ä—ã–≤–∞–µ—Ç—Å—è¬ª, —à–ª–µ–º –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏: {e}")
            try:
                # –ü—Ä–æ—Å—Ç–æ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –í–ï–°–¨ —Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º, –±–µ–∑ —Å–ª–æ–∂–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                fallback_text = escape_markdown(f"{used_prov}: {used_model}\n\n{reply_text}", version=2)
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_msg.message_id,
                    text=fallback_text,
                    parse_mode="MarkdownV2"
                )
            except Exception as e2:
                # –ü–õ–ê–ù –í: –í–æ–æ–±—â–µ –±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏, –µ—Å–ª–∏ –¥–∞–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Å–ø–∞—Å–ª–æ
                print(f"‚ùå –î–∞–∂–µ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç —É–ø–∞–ª: {e2}")
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_msg.message_id,
                    text=f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏. –û—Ç–≤–µ—Ç:\n\n{reply_text[:1000]}"
                )
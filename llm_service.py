#llm_service
import re
import requests, telegram
from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content
from collections import defaultdict
from telegram.helpers import escape_markdown

from config import (
    GEMINI_API_KEY, OPEN_ROUTER_API_KEY, WORKER_URL,
    SYSTEM_PROMPT_INSPECTOR, SYSTEM_PROMPT_CHAT, DEFAULT_OPENROUTER_MODELS, GEMINI_MODELS, API_TIMEOUT
)
from web_utils import get_web_context
from utils import safe_format_to_html, get_model_short_name

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
or_client = OpenAI(
    api_key=OPEN_ROUTER_API_KEY,
    base_url=f"{WORKER_URL}/v1",
    timeout=API_TIMEOUT
)

gemini_client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(base_url=WORKER_URL, timeout=int(API_TIMEOUT * 1000)),
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–µ–π ---
current_free_or_models = [DEFAULT_OPENROUTER_MODELS]
GEMINI_MODEL_BY_ID = {str(i): m for i, m in enumerate(GEMINI_MODELS)}
OPENROUTER_MODEL_BY_ID = {}
chat_histories = defaultdict(list)
BLACKLISTED_MODELS = set()


def fetch_dynamic_models():
    url = "https://openrouter.ai/api/v1/models"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            all_models = response.json().get('data', [])

            # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ä—É—á–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
            result = [m for m in DEFAULT_OPENROUTER_MODELS]

            for m in all_models:
                m_id = m.get('id', '')
                pricing = m.get('pricing', {})
                is_free = pricing.get('prompt') == "0" and pricing.get('completion') == "0"

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ä—É—á–Ω–æ–º —Å–ø–∏—Å–∫–µ
                if is_free and m_id not in result and m_id != "openrouter/free":
                    if m_id not in BLACKLISTED_MODELS:
                        result.append(m_id)

            return result[:15]
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
    return DEFAULT_OPENROUTER_MODELS


current_free_or_models = []  # –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏

def update_model_mappings():
    global current_free_or_models, OPENROUTER_MODEL_BY_ID

    new_models = fetch_dynamic_models()  # –¢–≤–æ—è –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞

    if new_models:
        current_free_or_models.clear()  # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π —Å–ø–∏—Å–æ–∫
        current_free_or_models.extend(new_models)  # –ù–∞–ø–æ–ª–Ω—è–µ–º —Ç–æ—Ç –∂–µ —Å–∞–º—ã–π –æ–±—ä–µ–∫—Ç

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–ø–ø–∏–Ω–≥ ID
        OPENROUTER_MODEL_BY_ID.clear()
        for i, m in enumerate(current_free_or_models):
            OPENROUTER_MODEL_BY_ID[str(i + 100)] = m


async def process_llm(update, context, query, selected_model=None, selected_provider=None, thread_id=None, mode="chat"):
    chat_id = update.effective_chat.id
    system_instruction = SYSTEM_PROMPT_INSPECTOR if mode == "inspector" else SYSTEM_PROMPT_CHAT

    # –û–¢–ü–†–ê–í–õ–Ø–ï–ú –°–¢–ê–¢–£–° –ë–ï–ó parse_mode
    status_text = "‚ö° –†–∞–±–æ—Ç–∞—é..." if mode != "inspector" else "üîç –í—Ö–æ–∂—É –≤ —Ä–µ–∂–∏–º –∏–Ω—Å–ø–µ–∫—Ç–æ—Ä–∞: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é..."
    status_msg = await context.bot.send_message(
        chat_id=chat_id,
        text=status_text,
        message_thread_id=thread_id
        # parse_mode –£–ë–†–ê–ù
    )

    final_query = query
    if mode == "inspector":
        # –†–ï–î–ê–ö–¢–ò–†–£–ï–ú –°–¢–ê–¢–£–° –ë–ï–ó parse_mode
        await context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=status_msg.message_id,
            text="üåê –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ..."
        )

        search_term = query.replace("–û–ë–™–ï–ö–¢ –ü–†–û–í–ï–†–ö–ò:", "").split("\n\n–í–û–ü–†–û–°:")[0].strip()
        web_data = await get_web_context(search_term)

        if web_data:
            # –°–ù–û–í–ê –ë–ï–ó parse_mode
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_msg.message_id,
                text="üß† –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã. –§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."
            )
            final_query = f"–î–ê–ù–ù–´–ï –ò–ó –°–ï–¢–ò:\n{web_data}\n\n–ó–ê–ü–†–û–°:\n{query}"

    # –ò—Å—Ç–æ—Ä–∏—è
    history = chat_histories[chat_id]
    history.append(Content(role="user", parts=[types.Part(text=query)]))
    chat_histories[chat_id] = history[-6:]

    # –û–ß–ï–†–ï–î–¨ –ú–û–î–ï–õ–ï–ô: –°–Ω–∞—á–∞–ª–∞ Trinity (–∏–ª–∏ —Ç–æ —á—Ç–æ –≤—ã–±—Ä–∞–ª —é–∑–µ—Ä), –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
    models_to_try = []
    if selected_model and selected_provider:
        models_to_try.append((selected_provider, selected_model))

    # –î–æ–±–∞–≤–ª—è–µ–º Gemini –≤ –∫–æ–Ω–µ—Ü –∫–∞–∫ –Ω–∞–¥–µ–∂–Ω—ã–π –±—ç–∫–∞–ø
    for m in GEMINI_MODELS:
        if ("gemini", m) not in models_to_try:
            models_to_try.append(("gemini", m))

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ OpenRouter
    for m in current_free_or_models:
        if ("openrouter", m) not in models_to_try:
            models_to_try.append(("openrouter", m))

    reply_text, used_model, used_prov = None, None, None
    for prov, m_path in models_to_try:
        if m_path in BLACKLISTED_MODELS:
            continue
        try:
            name_short = get_model_short_name(m_path, prov)
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∏ —É–±—Ä–∞–Ω Markdown, —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞–ª–æ
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_msg.message_id,
                text=f"üîÑ –ü—Ä–æ–±—É—é {prov}: {name_short}..."
            )
            if prov == "gemini":
                # –í–ê–ñ–ù–û: –¥–ª—è Gemini –º—ã –ø–µ—Ä–µ–¥–∞–µ–º final_query (—Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Å–µ—Ç–∏),
                # –Ω–æ –≤ –æ–±—â—É—é –∏—Å—Ç–æ—Ä–∏—é chat_histories —ç—Ç–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º!
                current_contents = [Content(role="model", parts=[types.Part(text=system_instruction)])]
                # –ë–µ—Ä–µ–º –∏—Å—Ç–æ—Ä–∏—é (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞) –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                current_contents += chat_histories[chat_id][:-1]
                current_contents.append(Content(role="user", parts=[types.Part(text=final_query)]))
                resp = gemini_client.models.generate_content(
                    model=m_path,
                    contents=current_contents
                )
                reply_text = resp.text
            else:
                # –î–ª—è OpenRouter –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ
                messages = [{"role": "system", "content": system_instruction}]
                # –ò—Å—Ç–æ—Ä–∏—è –±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                for h in chat_histories[chat_id][:-1]:
                    messages.append(
                        {"role": "user" if h.role == "user" else "assistant", "content": h.parts[0].text})
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                messages.append({"role": "user", "content": final_query})
                resp = or_client.chat.completions.create(
                    model=m_path,
                    messages=messages,
                    temperature=0.7,
                    extra_body={"repetition_penalty": 1.1}
                )
                reply_text = resp.choices[0].message.content
            if reply_text:
                used_model, used_prov = name_short, prov.capitalize()
                # –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –¥–æ–±–∞–≤–ª—è–µ–º –ï–ì–û –≤ –∏—Å—Ç–æ—Ä–∏—é
                chat_histories[chat_id].append(Content(role="model", parts=[types.Part(text=reply_text)]))
                break


        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ {m_path}: {e}")
            # –í—Ä–µ–º–µ–Ω–Ω–æ –±–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ 401/403/404 (–º–æ–¥–µ–ª–∏ –Ω–µ—Ç –∏–ª–∏ –ª–∏–º–∏—Ç)
            if "404" in str(e) or "401" in str(e):
                BLACKLISTED_MODELS.add(m_path)

    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    # ... (–ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è reply_text –æ—Ç –º–æ–¥–µ–ª–∏)
    if reply_text:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        clean_header = escape_markdown(f"{used_prov}: {used_model}", version=2)
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–ª–æ
        formatted_body = safe_format_to_html(reply_text)

        final_text = f"*{clean_header}*\n\n{formatted_body}"

        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∞—Å–∏–≤–æ
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_msg.message_id,
                text=final_text,
                parse_mode="MarkdownV2"
            )
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏: {e}")
            try:
                # –ü–ª–∞–Ω –ë: –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å—ë –∏ —à–ª–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (–¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤)
                fallback_text = escape_markdown(f"{used_prov}: {used_model}\n\n{reply_text}", version=2)
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_msg.message_id,
                    text=fallback_text[:4090],  # Telegram limit
                    parse_mode="MarkdownV2"
                )
            except:
                # –ü–ª–∞–Ω –í: –ï—Å–ª–∏ –¥–∞–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–±–æ–∏—Ç ‚Äî —à–ª–µ–º –ö–†–ê–°–ò–í–´–ú –ø—Ä–æ—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º –±–µ–∑ parse_mode
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_msg.message_id,
                    text=f"üìã –û—Ç–≤–µ—Ç (–±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏):\n\n{reply_text}"  # –£–±—Ä–∞–ª–∏ —Å—Ä–µ–∑ [:1000]
                )
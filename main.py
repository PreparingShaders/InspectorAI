import os
import asyncio
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters

from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content

from collections import defaultdict

load_dotenv()

InspectorGPT = os.getenv('InspectorGPT')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
BOT_USERNAME = os.getenv('BOT_USERNAME').lstrip("@").lower()  # –±–µ–∑ @
CORRECT_PASSWORD = os.getenv('Password')
OPEN_ROUTER_API_KEY = os.getenv('OPEN_ROUTER_API_KEY')

# ‚îÄ‚îÄ‚îÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini –∫–ª–∏–µ–Ω—Ç–∞ ‚îÄ‚îÄ‚îÄ
client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(
        base_url="https://inspectorgpt.classname1984.workers.dev"
    )
)

SYSTEM_PROMPT = '''
–¢—ã ‚Äî –ò–ò –ø–æ–º–æ—â–Ω–∏–∫.  
–¢–æ—á–Ω–∞—è, –ø–æ–Ω—è—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + —Ñ–∞–∫—Ç—á–µ–∫–∏–Ω–≥.  
–ü—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫. –ö—Ä–∞—Ç–∫–æ (‚â§300 –∑–Ω).  
–†–µ–¥–∫–∏–π —Ç–æ–Ω–∫–∏–π —é–º–æ—Ä –æ–∫. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥ Telegram  
–¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π. –Ø–Ω–≤–∞—Ä—å 2026.
'''

chat_histories = defaultdict(list)
authorized_users = set()

AUTH_QUESTION = "–¢—É—Ç —É –Ω–∞—Å –ø–∞—Ä–æ–ª—å. –ù—É–∂–Ω–æ –æ—Ç–≥–∞–¥–∞—Ç—å –∑–∞–≥–∞–¥–∫—É. –°–∫–∞–∂–∏, –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è —Ä–∞–∑–≥–æ–Ω—è–µ—Ç—Å—è –Ω–∏–≤–∞ –¥–æ 100 –∫–º/—á"

# --- –≠–¢–ê–ü 1: –ü—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ Google (–°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ---
# –≠—Ç–∏ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ —Ç–≤–æ–π –ø—Ä–æ–∫—Å–∏/Direct API.
MODELS_PRIORITY = [
    'models/gemini-3-flash-preview',      # –¢–≤–æ–π —Ç–µ–∫—É—â–∏–π –ª–∏–¥–µ—Ä (—É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!)
    'models/gemini-2.0-flash-lite',       # –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∫–æ–º–∞–Ω–¥
    'models/gemini-2.0-flash-exp'         # –•–æ—Ä–æ—à–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
]

# --- –≠–¢–ê–ü 2: OpenRouter (–¢–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏) ---
OPENROUTER_MODELS = [
    "xiaomi/mimo-v2-flash:free",          # –•–ò–¢ 2026: 309B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ—á–µ–Ω—å —É–º–Ω–∞—è
    "deepseek/deepseek-r1:free",          # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ (–∑–∞–º–µ–Ω–∞ —Å—Ç–∞—Ä–æ–º—É chat)
    "qwen/qwen3-235b-a22b:free",          # –ù–æ–≤–µ–π—à–∏–π Qwen 3 (–ª—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
    "meta-llama/llama-4-maverick:free",    # –ß–µ—Ç–≤–µ—Ä—Ç–æ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ Llama (Scout/Maverick)
    "mistralai/devstral-2-2512:free",     # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏–Ω–≥–∞ –∏ –ª–æ–≥–∏–∫–∏
    "microsoft/phi-4:free",               # –ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –æ—á–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
    "nousresearch/hermes-3-llama-3.1-405b:free" # –ó–∞–ø–∞—Å–Ω–æ–π –≥–∏–≥–∞–Ω—Ç
]
def is_bot_mentioned(message, bot_username: str) -> bool:
    if not message.entities:
        return False
    for entity in message.entities:
        if entity.type == "mention":
            mention_text = message.text[entity.offset: entity.offset + entity.length]
            if mention_text.lower() == f"@{bot_username.lower()}":
                return True
    return False


async def process_llm(update: Update, context, final_query: str):
    if not final_query or not final_query.strip():
        return

    chat_id = update.effective_chat.id
    # –î–ª—è –æ—Ç–≤–µ—Ç–∞ –≤ reply –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    reply_to_message_id = update.effective_message.message_id

    history = chat_histories.get(chat_id, [])
    history.append(Content(role="user", parts=[types.Part(text=final_query)]))
    chat_histories[chat_id] = history[-6:]

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å—Ç–∞—Ç—É—Å
    try:
        status_msg = await context.bot.send_message(
            chat_id=chat_id,
            text="‚ö° –ó–∞–ø—É—Å–∫–∞—é –º–æ–¥–µ–ª–∏...\n–ü—Ä–æ–±—É—é Gemini...",
            reply_to_message_id=reply_to_message_id,
            disable_notification=True
        )
        status_message_id = status_msg.message_id
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å: {e}")
        return

    reply_text = None
    used_provider = None
    last_used_model = ""

    # –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª–∏ Gemini –ø–æ –æ—á–µ—Ä–µ–¥–∏
    for current_model in MODELS_PRIORITY:
        try:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_message_id,
                text=f"üîÑ –ü—Ä–æ–±—É—é Gemini: {current_model.split('/')[-1]}..."
            )

            response = client.models.generate_content(
                model=current_model,
                contents=[Content(role="model", parts=[types.Part(text=SYSTEM_PROMPT)])] + history,
                config=GenerateContentConfig(
                    temperature=0.75,
                    max_output_tokens=512,
                    top_p=0.92
                )
            )

            if response and response.text:
                reply_text = response.text.strip()
                used_provider = "Gemini"
                last_used_model = current_model
                break

        except Exception as e:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_message_id,
                text=f"‚ùå {current_model.split('/')[-1]} –æ—à–∏–±–∫–∞\n–ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é..."
            )
            await asyncio.sleep(0.5)
            continue

    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî OpenRouter
    if not reply_text:
        await context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=status_message_id,
            text="‚ö†Ô∏è Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n‚Üí –ü–µ—Ä–µ—Ö–æ–∂—É –Ω–∞ OpenRouter..."
        )
        await asyncio.sleep(0.7)

        or_client = OpenAI(
            api_key=OPEN_ROUTER_API_KEY,
            base_url="https://openrouter.ai/api/v1",
        )

        or_messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        for msg in history:
            role = "user" if msg.role == "user" else "assistant"
            raw_text = msg.parts[0].text if hasattr(msg.parts[0], 'text') else str(msg.parts[0])
            or_messages.append({"role": role, "content": raw_text})

        for or_model in OPENROUTER_MODELS:
            try:
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_message_id,
                    text=f"üîÑ –ü—Ä–æ–±—É—é {or_model.split('/')[-1]} (OpenRouter)..."
                )

                response = or_client.chat.completions.create(
                    model=or_model,
                    messages=or_messages,
                    temperature=0.75,
                    max_tokens=512,
                    extra_headers={
                        "HTTP-Referer": "http://localhost",
                        "X-Title": "InspectorGPT",
                    }
                )

                if response.choices and response.choices[0].message.content:
                    reply_text = response.choices[0].message.content.strip()
                    used_provider = "OR"
                    last_used_model = or_model
                    break

            except Exception as e:
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_message_id,
                    text=f"‚ùå {or_model.split('/')[-1]} –æ—à–∏–±–∫–∞\n–°–ª–µ–¥—É—é—â–∞—è..."
                )
                await asyncio.sleep(0.5)
                continue

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
    model_short_name = last_used_model.split('/')[-1] if last_used_model else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    source_line = f"({used_provider}: {model_short_name})"

    if reply_text:
        chat_histories[chat_id].append(Content(role="model", parts=[types.Part(text=reply_text)]))

        full_text = f"{source_line}\n\n{reply_text}"

        # –ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å
        if len(full_text) <= 4000:
            try:
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_message_id,
                    text=full_text,
                    parse_mode="Markdown",
                    disable_web_page_preview=True
                )
                return
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –Ω–æ–≤–æ–µ
                pass

        # –î–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Äî —Ä–∞–∑–±–∏–≤–∞–µ–º
        await context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=status_message_id,
            text=f"{source_line}\n\n–û—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω—ã–π ‚Üí –æ—Ç–ø—Ä–∞–≤–ª—è—é —á–∞—Å—Ç—è–º–∏..."
        )

        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
        chunks = []
        current_chunk = ""
        for line in reply_text.splitlines(keepends=True):
            if len(current_chunk) + len(line) > 3900:
                chunks.append(current_chunk)
                current_chunk = line
            else:
                current_chunk += line
        if current_chunk:
            chunks.append(current_chunk)

        for i, chunk in enumerate(chunks, 1):
            part_text = f"–ß–∞—Å—Ç—å {i}/{len(chunks)}\n\n{chunk.strip()}"
            if i == 1:
                part_text = f"{source_line}\n\n{part_text}"

            await context.bot.send_message(
                chat_id=chat_id,
                text=part_text,
                reply_to_message_id=reply_to_message_id,
                parse_mode="Markdown",
                disable_notification=True,
                disable_web_page_preview=True
            )
            await asyncio.sleep(0.4)  # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏

    else:
        await context.bot.edit_message_text(
            chat_id=chat_id,
            message_id=status_message_id,
            text="‚ùå –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É-–¥–≤–µ."
        )
async def start(update: Update, context) -> None:
    user_id = update.effective_user.id
    if user_id in authorized_users:
        await update.message.reply_text("–¢—ã —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω!")
    else:
        await update.message.reply_text(AUTH_QUESTION)


async def handle_private(update: Update, context) -> None:
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if user_id not in authorized_users:
        if text.lower() == CORRECT_PASSWORD.lower():
            authorized_users.add(user_id)
            await update.message.reply_text(
                "–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞! üéâ\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—à—å –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã."
            )
        else:
            await update.message.reply_text(
                "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å üòï\n\n"
                "–ù–∞–ø–∏—à–∏ /start –∏ –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞"
            )
        return

    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ –ø–æ—Å–ª–µ strip ‚Äî –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    if not text:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å, —è –≥–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å üòè")
        return

    await process_llm(update, context, text)


async def handle_group(update: Update, context) -> None:
    message = update.message
    if not message or not message.text:
        return

    if not is_bot_mentioned(message, BOT_USERNAME):
        return

    # –£–±–∏—Ä–∞–µ–º @botname –∏–∑ —Ç–µ–∫—Å—Ç–∞
    clean_text = message.text
    for entity in message.entities or []:
        if entity.type == "mention":
            mention = message.text[entity.offset: entity.offset + entity.length]
            if mention.lower() == f"@{BOT_USERNAME.lower()}":
                clean_text = clean_text.replace(mention, "", 1).strip()
                break

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî reply
    prompt = ""
    if message.reply_to_message and message.reply_to_message.text:
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ): {message.reply_to_message.text}\n\n"

    prompt += clean_text

    if not prompt.strip():
        await message.reply_text("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ—Å–ª–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–µ–Ω—è üòè")
        return

    await process_llm(update, context, prompt)


def main() -> None:
    if not InspectorGPT:
        print("–û—à–∏–±–∫–∞: –¢–æ–∫–µ–Ω Telegram (InspectorGPT) –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    application = ApplicationBuilder().token(InspectorGPT).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & filters.ChatType.PRIVATE, handle_private))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND & ~filters.ChatType.PRIVATE, handle_group))
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


if __name__ == "__main__":
    main()
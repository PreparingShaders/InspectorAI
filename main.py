import os
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters

from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content

from collections import defaultdict

load_dotenv()

InspectorGPT = os.getenv('InspectorGPT')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
BOT_USERNAME = os.getenv('BOT_USERNAME').lstrip("@").lower()  # –±–µ–∑ @
CORRECT_PASSWORD = os.getenv('Password')
OPEN_ROUTER_API_KEY = os.getenv('OPEN_ROUTER_API_KEY')

# ‚îÄ‚îÄ‚îÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini –∫–ª–∏–µ–Ω—Ç–∞ ‚îÄ‚îÄ‚îÄ
client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(
        base_url="https://inspectorgpt.classname1984.workers.dev"
    )
)

SYSTEM_PROMPT = '''
–¢—ã ‚Äî –ò–ò –ø–æ–º–æ—â–Ω–∏–∫.  
–¢–æ—á–Ω–∞—è, –ø–æ–Ω—è—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + —Ñ–∞–∫—Ç—á–µ–∫–∏–Ω–≥.  
–ü—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫. –ö—Ä–∞—Ç–∫–æ (‚â§300 –∑–Ω).  
–†–µ–¥–∫–∏–π —Ç–æ–Ω–∫–∏–π —é–º–æ—Ä –æ–∫. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥ Telegram  
–¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π. –Ø–Ω–≤–∞—Ä—å 2026.
'''

chat_histories = defaultdict(list)
authorized_users = set()

AUTH_QUESTION = "–¢—É—Ç —É –Ω–∞—Å –ø–∞—Ä–æ–ª—å. –ù—É–∂–Ω–æ –æ—Ç–≥–∞–¥–∞—Ç—å –∑–∞–≥–∞–¥–∫—É. –°–∫–∞–∂–∏, –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è —Ä–∞–∑–≥–æ–Ω—è–µ—Ç—Å—è –Ω–∏–≤–∞ –¥–æ 100 –∫–º/—á"

# --- –≠–¢–ê–ü 1: –ü—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ Google (–°–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ---
# –≠—Ç–∏ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ —Ç–≤–æ–π –ø—Ä–æ–∫—Å–∏/Direct API.
MODELS_PRIORITY = [
    'models/gemini-3-flash-preview',      # –¢–≤–æ–π —Ç–µ–∫—É—â–∏–π –ª–∏–¥–µ—Ä (—É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!)
    'models/gemini-2.0-flash-lite',       # –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∫–æ–º–∞–Ω–¥
    'models/gemini-2.0-flash-exp'         # –•–æ—Ä–æ—à–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
]

# --- –≠–¢–ê–ü 2: OpenRouter (–¢–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏) ---
OPENROUTER_MODELS = [
    "xiaomi/mimo-v2-flash:free",          # –•–ò–¢ 2026: 309B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ—á–µ–Ω—å —É–º–Ω–∞—è
    "deepseek/deepseek-r1:free",          # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ (–∑–∞–º–µ–Ω–∞ —Å—Ç–∞—Ä–æ–º—É chat)
    "qwen/qwen3-235b-a22b:free",          # –ù–æ–≤–µ–π—à–∏–π Qwen 3 (–ª—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
    "meta-llama/llama-4-maverick:free",    # –ß–µ—Ç–≤–µ—Ä—Ç–æ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ Llama (Scout/Maverick)
    "mistralai/devstral-2-2512:free",     # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏–Ω–≥–∞ –∏ –ª–æ–≥–∏–∫–∏
    "microsoft/phi-4:free",               # –ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –æ—á–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
    "nousresearch/hermes-3-llama-3.1-405b:free" # –ó–∞–ø–∞—Å–Ω–æ–π –≥–∏–≥–∞–Ω—Ç
]
def is_bot_mentioned(message, bot_username: str) -> bool:
    if not message.entities:
        return False
    for entity in message.entities:
        if entity.type == "mention":
            mention_text = message.text[entity.offset: entity.offset + entity.length]
            if mention_text.lower() == f"@{bot_username.lower()}":
                return True
    return False


async def process_llm(update: Update, final_query: str):
    if not final_query or not final_query.strip():
        return

    chat_id = update.effective_chat.id
    history = chat_histories.get(chat_id, [])

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é (—Ñ–æ—Ä–º–∞—Ç Google Content)
    history.append(Content(role="user", parts=[types.Part(text=final_query)]))
    chat_histories[chat_id] = history[-6:]  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Ä–µ–ø–ª–∏–∫

    reply_text = None
    used_provider = None
    last_used_model = ""

    # --- –≠–¢–ê–ü 1: –ü—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ Gemini (Direct API) ---
    for current_model in MODELS_PRIORITY:
        try:
            print(f"üîÑ –ü—Ä–æ–±—É—é Gemini Direct: {current_model}")
            response = client.models.generate_content(
                model=current_model,
                contents=[Content(role="model", parts=[types.Part(text=SYSTEM_PROMPT)])] + history,
                config=GenerateContentConfig(
                    temperature=0.75,
                    max_output_tokens=512,
                    top_p=0.92
                )
            )

            if response and response.text:
                reply_text = response.text.strip()
                used_provider = "Gemini"
                last_used_model = current_model
                break  # –£—Å–ø–µ—Ö, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ Gemini

        except Exception as e:
            print(f"‚ùå Gemini {current_model} –æ—à–∏–±–∫–∞: {str(e)[:50]}")
            continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å Gemini

    # --- –≠–¢–ê–ü 2: Fallback –Ω–∞ OpenRouter (–ï—Å–ª–∏ Gemini Direct –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª) ---
    if not reply_text:
        print("‚ö†Ô∏è –í—Å–µ –ø—Ä—è–º—ã–µ Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–µ—Ä–µ—Ö–æ–∂—É –∫ OpenRouter...")

        or_client = OpenAI(
            api_key=OPEN_ROUTER_API_KEY,
            base_url="https://openrouter.ai/api/v1",
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤ Google –≤ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è OpenRouter
        or_messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        for msg in history:
            role = "user" if msg.role == "user" else "assistant"
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç, –¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç Part
            raw_text = msg.parts[0].text if hasattr(msg.parts[0], 'text') else str(msg.parts[0])
            or_messages.append({"role": role, "content": raw_text})

        for or_model in OPENROUTER_MODELS:
            try:
                print(f"üîÑ –ü—Ä–æ–±—É—é OpenRouter: {or_model}")
                response = or_client.chat.completions.create(
                    model=or_model,
                    messages=or_messages,
                    temperature=0.75,
                    max_tokens=512,
                    extra_headers={
                        "HTTP-Referer": "http://localhost",
                        "X-Title": "InspectorGPT",
                    }
                )

                if response.choices and response.choices[0].message.content:
                    reply_text = response.choices[0].message.content.strip()
                    used_provider = "OR"
                    last_used_model = or_model
                    break  # –£—Å–ø–µ—Ö, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ OpenRouter

            except Exception as e:
                print(f"‚ùå OR {or_model} –æ—à–∏–±–∫–∞: {str(e)[:100]}")
                continue  # –ï—Å–ª–∏ —ç—Ç–∞ –º–æ–¥–µ–ª—å –Ω–∞ OpenRouter "–ª–µ–∂–∏—Ç", –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ —Å–ø–∏—Å–∫—É

    # --- –§–ò–ù–ê–õ: –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ---
    if reply_text:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        chat_histories[chat_id].append(Content(role="model", parts=[types.Part(text=reply_text)]))

        # –ö—Ä–∞—Å–∏–≤–∞—è –ø–æ–º–µ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è –º–æ–¥–µ–ª–∏ –±–µ–∑ –ø—É—Ç–∏)
        model_short_name = last_used_model.split('/')[-1]
        final_reply = f"({used_provider}: {model_short_name})\n {reply_text}"
    else:
        final_reply = "‚ùå –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤—Å–µ –ò–ò-–º–æ–¥–µ–ª–∏ —Å–µ–π—á–∞—Å –∑–∞–Ω—è—Ç—ã –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."

    if update.message:
        try:
            await update.message.reply_text(final_reply[:4096])
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

async def start(update: Update, context) -> None:
    user_id = update.effective_user.id
    if user_id in authorized_users:
        await update.message.reply_text("–¢—ã —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω!")
    else:
        await update.message.reply_text(AUTH_QUESTION)


async def handle_private(update: Update, context) -> None:
    user_id = update.effective_user.id
    text = update.message.text.strip()
    if user_id not in authorized_users:
        if text.lower() == CORRECT_PASSWORD.lower():
            authorized_users.add(user_id)
            await update.message.reply_text("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞!")
        else:
            await update.message.reply_text("–¢—ã –µ—â–µ –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–π /start –∏ –≤–≤–µ–¥–∏ –ø–∞—Ä–æ–ª—å")
        return
    await process_llm(update, text)


async def handle_group(update: Update, context) -> None:
    message = update.message
    if not message or not message.text: return
    if not is_bot_mentioned(message, BOT_USERNAME): return

    text = message.text
    for entity in message.entities or []:
        if entity.type == "mention":
            mention = message.text[entity.offset: entity.offset + entity.length]
            if mention.lower() == f"@{BOT_USERNAME.lower()}":
                text = text.replace(mention, "", 1).strip()
                break

    context_text = ""
    if message.reply_to_message and message.reply_to_message.text:
        context_text = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ): {message.reply_to_message.text}\n\n"

    await process_llm(update, context_text + text)


def main() -> None:
    if not InspectorGPT:
        print("–û—à–∏–±–∫–∞: –¢–æ–∫–µ–Ω Telegram (InspectorGPT) –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    application = ApplicationBuilder().token(InspectorGPT).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & filters.ChatType.PRIVATE, handle_private))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND & ~filters.ChatType.PRIVATE, handle_group))
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


if __name__ == "__main__":
    main()
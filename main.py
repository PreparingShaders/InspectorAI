import os
import asyncio
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters

from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content

from collections import defaultdict

load_dotenv()

InspectorGPT = os.getenv('InspectorGPT')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
BOT_USERNAME = os.getenv('BOT_USERNAME', '').lstrip("@").lower()
CORRECT_PASSWORD = os.getenv('Password')
OPEN_ROUTER_API_KEY = os.getenv('OPEN_ROUTER_API_KEY')

# ‚îÄ‚îÄ‚îÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Gemini ‚îÄ‚îÄ‚îÄ
client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(
        base_url="https://inspectorgpt.classname1984.workers.dev"
    )
)

SYSTEM_PROMPT = '''
–¢—ã ‚Äî –ò–ò –ø–æ–º–æ—â–Ω–∏–∫. 
1. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ ‚Äî –æ—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (–¥–æ 300 –∑–Ω).
2. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç "–Ω–∞–ø–∏—à–∏ —Å–æ—á–∏–Ω–µ–Ω–∏–µ", "–ø–æ–¥—Ä–æ–±–Ω–æ", "—Å—Ç–∞—Ç—å—é" –∏–ª–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—ä–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5–∫ —Å–∏–º–≤–æ–ª–æ–≤) ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–π –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –∏ –ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ.
3. –¢–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + —Ñ–∞–∫—Ç—á–µ–∫–∏–Ω–≥. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –ø–æ–¥ Telegram.
4. –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –Ø–Ω–≤–∞—Ä—å 2026.
'''

chat_histories = defaultdict(list)
authorized_users = set()

AUTH_QUESTION = "–¢—É—Ç —É –Ω–∞—Å –ø–∞—Ä–æ–ª—å. –ù—É–∂–Ω–æ –æ—Ç–≥–∞–¥–∞—Ç—å –∑–∞–≥–∞–¥–∫—É. –°–∫–∞–∂–∏, –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è —Ä–∞–∑–≥–æ–Ω—è–µ—Ç—Å—è –Ω–∏–≤–∞ –¥–æ 100 –∫–º/—á"

MODELS_PRIORITY = [
    'models/gemini-3-flash-preview',
    'models/gemini-2.0-flash-lite',
    'models/gemini-2.0-flash-exp'
]

OPENROUTER_MODELS = [
    "xiaomi/mimo-v2-flash:free",
    "deepseek/deepseek-r1:free",
    "qwen/qwen3-235b-a22b:free",
    "meta-llama/llama-4-maverick:free",
    "mistralai/devstral-2-2512:free",
    "microsoft/phi-4:free",
    "nousresearch/hermes-3-llama-3.1-405b:free"
]

def escape_md_v2_full(text: str) -> str:
    """–ü–æ–ª–Ω–æ–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è MarkdownV2 ‚Äî –≤—Å–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã"""
    special = r'_*[]()~`>#+-=|{}.!'
    return ''.join('\\' + c if c in special else c for c in text)

def is_bot_mentioned(message, bot_username: str) -> bool:
    if not message.entities:
        return False
    for entity in message.entities:
        if entity.type == "mention":
            mention_text = message.text[entity.offset: entity.offset + entity.length]
            if mention_text.lower() == f"@{bot_username.lower()}":
                return True
    return False


async def process_llm(update: Update, context, final_query: str):
    if not final_query or not final_query.strip():
        return

    chat_id = update.effective_chat.id
    reply_to_message_id = update.effective_message.message_id

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    history = chat_histories.get(chat_id, [])
    history.append(Content(role="user", parts=[types.Part(text=final_query)]))
    chat_histories[chat_id] = history[-6:]

    # –°—Ç–∞—Ç—É—Å
    try:
        status_msg = await context.bot.send_message(
            chat_id=chat_id,
            text="‚ö° –ó–∞–ø—É—Å–∫–∞—é –º–æ–¥–µ–ª–∏...",
            reply_to_message_id=reply_to_message_id
        )
        status_message_id = status_msg.message_id
    except:
        return

    reply_text = None
    used_provider = None
    last_used_model = ""

    # –í–ê–ñ–ù–û: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –∏ –¥–ª–∏–Ω—ã
    ADAPTIVE_SYSTEM_PROMPT = SYSTEM_PROMPT + "\n–í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–æ—á–∏–Ω–µ–Ω–∏–µ ‚Äî –ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ª–∏–º–∏—Ç 300 –∑–Ω. –ò—Å–ø–æ–ª—å–∑—É–π HTML-—Ç–µ–≥–∏: <b>–∂–∏—Ä–Ω—ã–π</b>, <i>–∫—É—Ä—Å–∏–≤</i>."

    # ‚îÄ‚îÄ‚îÄ 1. Gemini ‚îÄ‚îÄ‚îÄ
    for model_path in MODELS_PRIORITY:
        model_name = model_path.split('/')[-1]
        try:
            await context.bot.edit_message_text(chat_id=chat_id, message_id=status_message_id,
                                                text=f"üîÑ Gemini: {model_name}...")

            response = client.models.generate_content(
                model=model_path,
                contents=[Content(role="model", parts=[types.Part(text=ADAPTIVE_SYSTEM_PROMPT)])] + history,
                config=GenerateContentConfig(
                    temperature=0.75,
                    max_output_tokens=4000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                    top_p=0.92
                )
            )
            if response and response.text:
                reply_text = response.text.strip()
                used_provider = "Gemini"
                last_used_model = model_path
                break
        except:
            continue

    # ‚îÄ‚îÄ‚îÄ 2. OpenRouter Fallback ‚îÄ‚îÄ‚îÄ
    if not reply_text:
        or_client = OpenAI(api_key=OPEN_ROUTER_API_KEY, base_url="https://openrouter.ai/api/v1")
        or_messages = [{"role": "system", "content": ADAPTIVE_SYSTEM_PROMPT}]
        for msg in history:
            role = "user" if msg.role == "user" else "assistant"
            text_part = msg.parts[0].text if hasattr(msg.parts[0], 'text') else str(msg.parts[0])
            or_messages.append({"role": role, "content": text_part})

        for model_path in OPENROUTER_MODELS:
            model_name = model_path.split('/')[-1]
            try:
                await context.bot.edit_message_text(chat_id=chat_id, message_id=status_message_id,
                                                    text=f"üîÑ OR: {model_name}...")
                response = or_client.chat.completions.create(
                    model=model_path,
                    messages=or_messages,
                    temperature=0.75,
                    max_tokens=4000  # –£–≤–µ–ª–∏—á–µ–Ω–æ
                )
                if response.choices and response.choices[0].message.content:
                    reply_text = response.choices[0].message.content.strip()
                    used_provider = "OR"
                    last_used_model = model_path
                    break
            except:
                continue

    # ‚îÄ‚îÄ‚îÄ 3. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ (–í–ù–ï –¶–ò–ö–õ–û–í) ‚îÄ‚îÄ‚îÄ
    if not reply_text:
        await context.bot.edit_message_text(chat_id=chat_id, message_id=status_message_id, text="‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    chat_histories[chat_id].append(Content(role="model", parts=[types.Part(text=reply_text)]))

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å HTML
    model_short = last_used_model.split('/')[-1]
    full_reply = f"<b>{used_provider}: {model_short}</b>\n\n{reply_text}"

    # Telegram limit ~4096
    MAX_LEN = 4000

    if len(full_reply) <= MAX_LEN:
        try:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_message_id,
                text=full_reply,
                parse_mode='HTML',
                disable_web_page_preview=True
            )
        except Exception as e:
            # –ï—Å–ª–∏ HTML —Å–ª–æ–º–∞–ª—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ò–ò –∑–∞–±—ã–ª –∑–∞–∫—Ä—ã—Ç—å —Ç–µ–≥ </b>), —à–ª–µ–º —á–∏—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º
            await context.bot.edit_message_text(chat_id=chat_id, message_id=status_message_id, text=full_reply,
                                                parse_mode=None)
    else:
        # –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ —à–ª–µ–º —á–∞—Å—Ç—è–º–∏
        try:
            await context.bot.delete_message(chat_id=chat_id, message_id=status_message_id)
        except:
            pass

        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        for i in range(0, len(full_reply), MAX_LEN):
            part = full_reply[i:i + MAX_LEN]
            try:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=part,
                    parse_mode='HTML',
                    reply_to_message_id=reply_to_message_id if i == 0 else None
                )
            except:
                await context.bot.send_message(chat_id=chat_id, text=part, parse_mode=None)
            await asyncio.sleep(0.5)

async def start(update: Update, context) -> None:
    user_id = update.effective_user.id
    if user_id in authorized_users:
        await update.message.reply_text("–¢—ã —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω!")
    else:
        await update.message.reply_text(AUTH_QUESTION)


async def handle_private(update: Update, context) -> None:
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if user_id not in authorized_users:
        if text.lower() == CORRECT_PASSWORD.lower():
            authorized_users.add(user_id)
            await update.message.reply_text("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞! üéâ\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—à—å –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã.")
        else:
            await update.message.reply_text("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å üòï\n\n–ù–∞–ø–∏—à–∏ /start –∏ –ø–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞")
        return

    if not text:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å, —è –≥–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å üòè")
        return

    await process_llm(update, context, text)


async def handle_group(update: Update, context) -> None:
    message = update.message
    if not message or not message.text:
        return

    if not is_bot_mentioned(message, BOT_USERNAME):
        return

    clean_text = message.text
    for entity in message.entities or []:
        if entity.type == "mention":
            mention = message.text[entity.offset: entity.offset + entity.length]
            if mention.lower() == f"@{BOT_USERNAME.lower()}":
                clean_text = clean_text.replace(mention, "", 1).strip()
                break

    prompt = ""
    if message.reply_to_message and message.reply_to_message.text:
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ): {message.reply_to_message.text}\n\n"
    prompt += clean_text

    if not prompt.strip():
        await message.reply_text("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ—Å–ª–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–µ–Ω—è üòè")
        return

    await process_llm(update, context, prompt)


def main() -> None:
    if not InspectorGPT:
        print("–û—à–∏–±–∫–∞: –¢–æ–∫–µ–Ω Telegram (InspectorGPT) –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    application = ApplicationBuilder().token(InspectorGPT).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & filters.ChatType.PRIVATE, handle_private))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND & ~filters.ChatType.PRIVATE, handle_group))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()


if __name__ == "__main__":
    main()
import os
import asyncio
import re
from collections import defaultdict

from dotenv import load_dotenv

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
)

from openai import OpenAI
from google import genai
from google.genai import types
from google.genai.types import GenerateContentConfig, Content

load_dotenv()

# ‚îÄ‚îÄ‚îÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BOT_TOKEN = os.getenv("InspectorGPT")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
BOT_USERNAME = os.getenv("BOT_USERNAME", "").lstrip("@").lower()
CORRECT_PASSWORD = os.getenv("Password")
OPEN_ROUTER_API_KEY = os.getenv("OPEN_ROUTER_API_KEY")

GEMINI_MODELS = [
    "models/gemini-3-flash-preview",
    "models/gemini-2.0-flash-lite",
    "models/gemini-2.0-flash-exp",
]

OPENROUTER_MODELS = [
    "xiaomi/mimo-v2-flash:free",
    "allenai/molmo-2-8b:free",
    "google/gemma-3-27b-it:free",
    "nousresearch/hermes-3-llama-3.1-405b:free",
    "nvidia/nemotron-3-nano-30b-a3b:free",
    "mistralai/devstral-2-2512:free",
    "tngtech/deepseek-r1t2-chimera:free",
    "deepseek/deepseek-r1:free",
    "meta-llama/llama-4-maverick:free",
    "qwen/qwen3-235b-a22b:free",
    "microsoft/phi-4:free",
    "qwen/qwen2.5-vl-32b-instruct:free",
    "deepseek/deepseek-v3-base:free",
    "xai/grok-3-mini:free",
]

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∫–æ–¥–æ–≤ ‚Üí –ø–æ–ª–Ω—ã–µ –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π
GEMINI_MODEL_BY_ID = {str(i): path for i, path in enumerate(GEMINI_MODELS)}
OPENROUTER_MODEL_BY_ID = {str(i + 100): path for i, path in enumerate(OPENROUTER_MODELS)}

# ‚îÄ‚îÄ‚îÄ –•—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
chat_histories = defaultdict(list)
authorized_users = set()
user_selected_model = defaultdict(lambda: None)          # –ø–æ–ª–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ –∏–ª–∏ None
user_selected_provider = defaultdict(lambda: "gemini")   # "gemini" –∏–ª–∏ "openrouter"

# ‚îÄ‚îÄ‚îÄ –ö–ª–∏–µ–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
gemini_client = genai.Client(
    api_key=GEMINI_API_KEY,
    http_options=types.HttpOptions(base_url="https://inspectorgpt.classname1984.workers.dev"),
)

openrouter_client = OpenAI(
    api_key=OPEN_ROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
)

SYSTEM_PROMPT = '''
–¢—ã ‚Äî –ò–ò –ø–æ–º–æ—â–Ω–∏–∫. 
1. –¢–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + —Ñ–∞–∫—Ç—á–µ–∫–∏–Ω–≥.–£–∫–∞–∂–∏ –Ω–∞ —Å–∫–æ–ª—å–∫–æ % —ç—Ç–æ –ø—Ä–∞–≤–¥–∞.
2. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç "–Ω–∞–ø–∏—à–∏ —Å–æ—á–∏–Ω–µ–Ω–∏–µ", "–ø–æ–¥—Ä–æ–±–Ω–æ", "—Å—Ç–∞—Ç—å—é" –∏–ª–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—ä–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5–∫ —Å–∏–º–≤–æ–ª–æ–≤) ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–π –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –∏ –ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ.
3. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ ‚Äî –æ—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (–¥–æ 300 –∑–Ω).
4. –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –Ø–Ω–≤–∞—Ä—å 2026. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π –ø–æ–¥ Telegram.
'''

AUTH_QUESTION = "–¢—É—Ç —É –Ω–∞—Å –ø–∞—Ä–æ–ª—å. –ù—É–∂–Ω–æ –æ—Ç–≥–∞–¥–∞—Ç—å –∑–∞–≥–∞–¥–∫—É. –°–∫–∞–∂–∏, –∑–∞ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è —Ä–∞–∑–≥–æ–Ω—è–µ—Ç—Å—è –Ω–∏–≤–∞ –¥–æ 100 –∫–º/—á"


def escape_md_v2_full(text: str) -> str:
    special = r'_*[]()~`>#+-=|{}.!'
    return ''.join('\\' + c if c in special else c for c in text)


def is_bot_mentioned(message, bot_username: str) -> bool:
    if not message.entities:
        return False
    for entity in message.entities:
        if entity.type == "mention":
            mention_text = message.text[entity.offset: entity.offset + entity.length]
            if mention_text.lower() == f"@{bot_username.lower()}":
                return True
    return False


def format_to_html(text: str) -> str:
    text = re.sub(r'(\*\*|__)(.*?)\1', r'<b>\2</b>', text)
    text = re.sub(r'(\*|_)(.*?)\1', r'<i>\2</i>', text)
    text = re.sub(r'`(.*?)`', r'<code>\1</code>', text)
    text = re.sub(r'```(?:.*?)\n?(.*?)```', r'<pre>\1</pre>', text, flags=re.DOTALL)
    return text


def get_model_short_name(model_path: str, provider: str) -> str:
    if provider == "gemini":
        return model_path.split("/")[-1].replace("models/", "")
    else:
        return model_path.split("/")[-1].split(":")[0]


async def show_model_selection(update: Update, context):
    """–ü–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
    user_id = update.effective_user.id
    keyboard = []

    keyboard.append([InlineKeyboardButton("Gemini:", callback_data="dummy")])
    for i, model in enumerate(GEMINI_MODELS):
        name = get_model_short_name(model, "gemini")
        prefix = "‚úÖ " if user_selected_model[user_id] == model else ""
        keyboard.append([
            InlineKeyboardButton(f"{prefix}{name}", callback_data=f"sel:g:{i}")
        ])

    keyboard.append([InlineKeyboardButton("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ", callback_data="dummy")])

    keyboard.append([InlineKeyboardButton("OpenRouter:", callback_data="dummy")])
    for i, model in enumerate(OPENROUTER_MODELS):
        name = get_model_short_name(model, "openrouter")
        prefix = "‚úÖ " if user_selected_model[user_id] == model else ""
        keyboard.append([
            InlineKeyboardButton(f"{prefix}{name}", callback_data=f"sel:o:{i+100}")
        ])

    keyboard.append([
        InlineKeyboardButton("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä", callback_data="sel:auto")
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=reply_markup)


async def callback_handler(update: Update, context):
    query = update.callback_query
    await query.answer()

    data = query.data
    user_id = query.from_user.id

    if data == "dummy":
        return

    if data == "sel:auto":
        user_selected_model[user_id] = None
        user_selected_provider[user_id] = "gemini"
        await query.edit_message_text("–í–µ—Ä–Ω—É–ª—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
        return

    if not data.startswith("sel:"):
        return

    try:
        _, prov_short, idx_str = data.split(":")
        idx = int(idx_str)
    except:
        await query.edit_message_text("–û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏")
        return

    model_path = None
    provider = None

    if prov_short == "g":
        model_path = GEMINI_MODEL_BY_ID.get(idx_str)
        provider = "gemini"
    elif prov_short == "o":
        model_path = OPENROUTER_MODEL_BY_ID.get(idx_str)
        provider = "openrouter"

    if model_path:
        user_selected_model[user_id] = model_path
        user_selected_provider[user_id] = provider
        name = get_model_short_name(model_path, provider)
        await query.edit_message_text(f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å:\n{provider.upper()} ‚Üí {name}")
    else:
        await query.edit_message_text("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å")

async def process_llm(update: Update, context, final_query: str):
    if not final_query.strip():
        return

    chat_id = update.effective_chat.id
    reply_to_message_id = update.effective_message.message_id
    user_id = update.effective_user.id

    history = chat_histories[chat_id]
    history.append(Content(role="user", parts=[types.Part(text=final_query)]))
    chat_histories[chat_id] = history[-6:]

    status_msg = await context.bot.send_message(
        chat_id=chat_id,
        text="‚ö° –ó–∞–ø—É—Å–∫–∞—é –º–æ–¥–µ–ª–∏...",
        reply_to_message_id=reply_to_message_id
    )
    status_id = status_msg.message_id

    reply_text = None
    used_provider = None
    used_model_path = None

    ADAPTIVE_SYSTEM_PROMPT = SYSTEM_PROMPT + "\n–í–ê–ñ–ù–û: –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–æ—á–∏–Ω–µ–Ω–∏–µ ‚Äî –ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ª–∏–º–∏—Ç 300 –∑–Ω.–Ø–Ω–≤–∞—Ä—å 2026. –ò—Å–ø–æ–ª—å–∑—É–π HTML-—Ç–µ–≥–∏: <b>–∂–∏—Ä–Ω—ã–π</b>, <i>–∫—É—Ä—Å–∏–≤</i>."

    selected_model = user_selected_model[user_id]
    selected_provider = user_selected_provider[user_id]

    # 1. –ü—Ä–æ–±—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞)
    if selected_model:
        try:
            await context.bot.edit_message_text(
                chat_id=chat_id, message_id=status_id,
                text=f"üîÑ –ü—Ä–æ–±—É—é –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {selected_model.split('/')[-1]}..."
            )

            if selected_provider == "gemini":
                response = gemini_client.models.generate_content(
                    model=selected_model,
                    contents=[Content(role="model", parts=[types.Part(text=ADAPTIVE_SYSTEM_PROMPT)])] + history,
                    config=GenerateContentConfig(temperature=0.75, max_output_tokens=4000, top_p=0.92)
                )
                if response and response.text:
                    reply_text = response.text.strip()
                    used_provider = "Gemini"
                    used_model_path = selected_model

            else:  # openrouter
                messages = [{"role": "system", "content": ADAPTIVE_SYSTEM_PROMPT}]
                for msg in history:
                    role = "user" if msg.role == "user" else "assistant"
                    content = msg.parts[0].text if msg.parts else ""
                    messages.append({"role": role, "content": content})

                response = openrouter_client.chat.completions.create(
                    model=selected_model,
                    messages=messages,
                    temperature=0.75,
                    max_tokens=4000
                )
                if response.choices and response.choices[0].message.content:
                    reply_text = response.choices[0].message.content.strip()
                    used_provider = "OpenRouter"
                    used_model_path = selected_model


        except Exception:
            model_name = get_model_short_name(selected_model, selected_provider)
            prov = selected_provider.upper()
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_id,
                text=(
                    f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {prov} ‚Üí {model_name}\n\n"
                    "–í—ã–±–µ—Ä–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å:\n"
                    "‚Üí –∫–æ–º–∞–Ω–¥–∞ /model"
                )
            )
            await asyncio.sleep(3)
            try:
                await context.bot.delete_message(chat_id=chat_id, message_id=status_id)
            except Exception:
                pass
            return  # ‚Üê –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ! –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é

    # 2. –û–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä, –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å
    if reply_text is None:
        # Gemini
        for model_path in GEMINI_MODELS:
            try:
                await context.bot.edit_message_text(
                    chat_id=chat_id, message_id=status_id,
                    text=f"üîÑ Gemini: {model_path.split('/')[-1]}..."
                )

                response = gemini_client.models.generate_content(
                    model=model_path,
                    contents=[Content(role="model", parts=[types.Part(text=ADAPTIVE_SYSTEM_PROMPT)])] + history,
                    config=GenerateContentConfig(temperature=0.75, max_output_tokens=4000, top_p=0.92)
                )
                if response and response.text:
                    reply_text = response.text.strip()
                    used_provider = "Gemini"
                    used_model_path = model_path
                    break
            except Exception:
                continue

        # OpenRouter fallback
        if reply_text is None:
            messages = [{"role": "system", "content": ADAPTIVE_SYSTEM_PROMPT}]
            for msg in history:
                role = "user" if msg.role == "user" else "assistant"
                content = msg.parts[0].text if msg.parts else ""
                messages.append({"role": role, "content": content})

            for model_path in OPENROUTER_MODELS:
                try:
                    await context.bot.edit_message_text(
                        chat_id=chat_id, message_id=status_id,
                        text=f"üîÑ OR: {model_path.split('/')[-1].split(':')[0]}..."
                    )
                    response = openrouter_client.chat.completions.create(
                        model=model_path,
                        messages=messages,
                        temperature=0.75,
                        max_tokens=4000
                    )
                    if response.choices and response.choices[0].message.content:
                        reply_text = response.choices[0].message.content.strip()
                        used_provider = "OpenRouter"
                        used_model_path = model_path
                        break
                except Exception:
                    continue

    # 3. –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if reply_text is None:
        await context.bot.edit_message_text(
            chat_id=chat_id, message_id=status_id,
            text="‚ùå –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã üòî"
        )
        return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
    chat_histories[chat_id].append(Content(role="model", parts=[types.Part(text=reply_text)]))

    model_short = used_model_path.split("/")[-1].split(":")[0]
    full_reply = f"<b>{used_provider}: {model_short}</b>\n\n{format_to_html(reply_text)}"

    # –û—Ç–ø—Ä–∞–≤–∫–∞ (—Ç–≤–æ–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å —Å—é–¥–∞)
    MAX_LEN = 4000
    if len(full_reply) <= MAX_LEN:
        try:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_id,
                text=full_reply,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
        except:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=status_id,
                text=full_reply,
                parse_mode=None
            )
    else:
        # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞—Å—Ç–∏ ‚Äî –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –±—ã–ª–æ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        await context.bot.delete_message(chat_id=chat_id, message_id=status_id)
        # ... –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å —Ç–≤–æ—é –ª–æ–≥–∏–∫—É —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏


# ‚îÄ‚îÄ‚îÄ Handlers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def start(update: Update, context):
    user_id = update.effective_user.id
    if user_id in authorized_users:
        model = user_selected_model[user_id]
        text = "–¢—ã —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω!\n\n"
        if model:
            prov = user_selected_provider[user_id].upper()
            name = model.split("/")[-1].split(":")[0]
            text += f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {prov} ‚Üí {name}\n\n"
        text += "–°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å ‚Üí /model"
        await update.message.reply_text(text)
    else:
        await update.message.reply_text(AUTH_QUESTION)


async def handle_private(update: Update, context):
    user_id = update.effective_user.id
    message = update.message
    if not message:
        return

    text = (message.text or message.caption or "").strip()

    if user_id not in authorized_users:
        if text.lower() == CORRECT_PASSWORD.lower():
            authorized_users.add(user_id)
            await message.reply_text("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞! üéâ\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—à—å –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã.\n\n/model ‚Äî –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏")
        else:
            await message.reply_text("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å üòï")
        return

    if not text:
        await message.reply_text("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≤ –ø–æ–¥–ø–∏—Å–∏ –∫ —Ñ–æ—Ç–æ üòè")
        return

    await process_llm(update, context, text)


async def handle_group(update: Update, context):
    message = update.message
    if not message:
        return

    content = message.text or message.caption or ""
    if not content:
        return

    if not is_bot_mentioned(message, BOT_USERNAME):
        return

    clean_text = content
    for entity in (message.entities or []) + (message.caption_entities or []):
        if entity.type == "mention":
            mention = content[entity.offset : entity.offset + entity.length]
            if mention.lower() == f"@{BOT_USERNAME.lower()}":
                clean_text = clean_text.replace(mention, "", 1).strip()
                break

    prompt = ""
    if message.reply_to_message:
        reply = message.reply_to_message
        reply_text = reply.text or reply.caption or ""
        if reply_text:
            prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (–æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ): {reply_text}\n\n"

    prompt += clean_text.strip()

    if not prompt:
        await message.reply_text("–ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –ø–æ—Å–ª–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–µ–Ω—è üòè")
        return

    await process_llm(update, context, prompt)


def main():
    if not BOT_TOKEN:
        print("–û—à–∏–±–∫–∞: –¢–æ–∫–µ–Ω Telegram –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("model", show_model_selection))
    app.add_handler(CallbackQueryHandler(callback_handler))

    message_filter = filters.TEXT | filters.PHOTO | filters.VIDEO | filters.Document.ALL

    app.add_handler(MessageHandler(message_filter & filters.ChatType.PRIVATE, handle_private))
    app.add_handler(MessageHandler(message_filter & ~filters.COMMAND & ~filters.ChatType.PRIVATE, handle_group))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ö–æ–º–∞–Ω–¥–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏: /model")
    app.run_polling()


if __name__ == "__main__":
    main()